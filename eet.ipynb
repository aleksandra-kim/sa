{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brightway2 as bw\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose a project and run LCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw.projects.set_current(\"SA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Databases dictionary with 2 object(s):\n",
       "\tbiosphere3\n",
       "\tecoinvent 3.5 cutoff"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bw.databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'ecoinvent 3.5 cutoff'\n",
    "db = bw.Database(db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "act = db.random()\n",
    "act_amount = 1.0 #unit demand vector\n",
    "ipcc2013 = [m for m in bw.methods if 'IPCC' in m[0]\n",
    "                        and ('2013') in str(m)\n",
    "                        and 'GWP 100' in str(m)\n",
    "                        and 'no LT' not in str(m)]\n",
    "lca = bw.LCA({act:act_amount}, ipcc2013[0])\n",
    "lca.lci()\n",
    "lca.lcia()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. create a vector tech_params identical to lca.tech_params but with an additional column for indices $1,2,...,n_{params}$ and dtype.name $i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#augmented dtype\n",
    "dt = lca.tech_params.dtype.descr\n",
    "dt.insert(0,('i','<i4'))\n",
    "dt = np.dtype(dt)\n",
    "\n",
    "#number of parameters\n",
    "n_params = lca.tech_params.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lca.tech_params augmented with the index on the first position\n",
    "tech_params = np.zeros([n_params],dtype=dt)\n",
    "i = 0\n",
    "for x in lca.tech_params:\n",
    "    temp = list(x)\n",
    "    temp.insert(0,i)\n",
    "    tech_params[i] = tuple(temp)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate samples for EET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate uniformly distributed samples ($\\in [0,1]$) using SALib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SALib.sample import morris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IDs for distributions from stats_array\n",
    "id_na = 0 #no distribution available\n",
    "id_lg = 2 #lognormal\n",
    "id_nm = 3 #normal\n",
    "id_tr = 5 #triangular\n",
    "\n",
    "#all uncertain parameters\n",
    "params = tech_params[tech_params['uncertainty_type']!=id_na][:10] #TODO change this eventually\n",
    "n_vars = len(params)\n",
    "names  = [str(x) for x in params['i']]\n",
    "bounds = np.array([np.zeros(n_vars),np.ones(n_vars)]).T #Always [0,1]!\n",
    "#samples info\n",
    "n_tra = 200          #number of trajectories\n",
    "p     = 8           #number of levels, even number recommended\n",
    "delta = p/(2*(p-1)) #grid jump recommended in papers\n",
    "#problem\n",
    "problem = {\n",
    "    'num_vars':   n_vars,\n",
    "    'num_levels': p,\n",
    "    'names':      names,\n",
    "    'bounds':     bounds,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2200"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generate samples\n",
    "samples = morris.sample(problem, n_tra, num_levels=p)\n",
    "N = samples.shape[0]\n",
    "N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert uniform samples to original distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import lognorm, norm, triang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#give dtype with names to distinguish between input factors\n",
    "data_type = [('<f4') for x in range(n_vars)]\n",
    "dt = np.array([names,data_type]).T\n",
    "dt = [tuple(x) for x in dt]\n",
    "dt = np.dtype(dt)\n",
    "\n",
    "samples_dt = np.zeros([N],dtype = dt)\n",
    "i = 0\n",
    "for x in samples:\n",
    "    temp = list(x)\n",
    "    samples_dt[i] = tuple(temp)\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_original_pdf(problem,params,samples_uniform,id_distr):\n",
    "    \n",
    "    inds = params[params['uncertainty_type']==id_distr]['i']\n",
    "    \n",
    "    if len(inds)<=0:\n",
    "        return np.zeros(0)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        #calculate area under 6 sigma interval of the normal distribution\n",
    "        from math import exp, pi\n",
    "        from scipy.integrate import quad\n",
    "        s = 1\n",
    "        m = 0\n",
    "        six_sigma_q = quad(lambda x: 1/np.sqrt(2*pi*s**2)*exp(-(x-m)**2/(2*s**2)),-3*s, 3*s)[0]\n",
    "        \n",
    "        #IDs for distributions from stats_array\n",
    "        id_na = 0 #no distribution available\n",
    "        id_lg = 2 #lognormal\n",
    "        id_nm = 3 #normal\n",
    "        id_tr = 5 #triangular\n",
    "        \n",
    "        names = [str(x) for x in inds]\n",
    "        bounds = problem['bounds']\n",
    "        \n",
    "        #Quantiles are the same for all distributions given the level p\n",
    "        q_lo = (1-six_sigma_q)/2\n",
    "        q_hi = (1+six_sigma_q)/2\n",
    "        p = problem['num_levels']\n",
    "        q = np.linspace(q_lo,q_hi,p)\n",
    "        \n",
    "        #new (original) distributions\n",
    "        samples_conv = np.zeros_like(samples_uniform[names])\n",
    "   \n",
    "        #lognormal\n",
    "        if id_distr == id_lg: \n",
    "            \n",
    "            for name in names:\n",
    "                \n",
    "                x = samples_uniform[name]\n",
    "                \n",
    "                #old uniform distribution\n",
    "                i = problem['names'].index(name)\n",
    "                width = bounds[i,1]-bounds[i,0]\n",
    "                \n",
    "                #convert x to percentages q within the 6 sigma interval\n",
    "                q = [xx*six_sigma_q/width+(1-six_sigma_q)/2 for xx in set(x)] \n",
    "                print(len(q))\n",
    "                \n",
    "                #new distribution\n",
    "                #in bw:            loc=mu, scale=sigma, where mu and sigma are from the normal distribution\n",
    "                #in stats.lognorm: loc=shift, s=sigma, scale=exp(mu), where mu and sigma are from the normal distribution \n",
    "                input_factor = params[params['i']==int(name)]\n",
    "                mu = input_factor['loc']\n",
    "                sigma  = input_factor['scale']\n",
    "                shift = 0\n",
    "                \n",
    "                #Converted samples generated using ppf (=inverse of cdf)\n",
    "                conv_unique = lognorm.ppf(q,s=sigma,loc=shift,scale=np.exp(mu))\n",
    "                print(q)\n",
    "                samples_conv[name] = 1 \n",
    "                                \n",
    "        #normal\n",
    "        elif id_distr == id_nm:\n",
    "            \n",
    "            for name in names:\n",
    "                \n",
    "                x = samples_uniform[name]\n",
    "                \n",
    "                #old uniform distribution\n",
    "                i = problem['names'].index(name)\n",
    "                width = bounds[i,1]-bounds[i,0]\n",
    "                \n",
    "                #convert x to percentages q within the 6 sigma interval\n",
    "                q = [xx*six_sigma_q/width+(1-six_sigma_q)/2 for xx in x]\n",
    "                \n",
    "                #new distribution\n",
    "                #in bw:         loc=mu, scale=sigma, where mu and sigma are mean and std\n",
    "                #in stats.norm: loc=mu, scale=sigma, where mu and sigma are mean and std \n",
    "                input_factor = params[params['i']==int(name)]\n",
    "                mu = input_factor['loc']\n",
    "                sigma  = input_factor['scale']\n",
    "                \n",
    "                #Converted samples generated using ppf (=inverse of cdf)\n",
    "                samples_conv[name] = norm.ppf(q,loc=mu,scale=sigma)\n",
    "                                \n",
    "        #triangular\n",
    "        elif id_distr == id_tr:\n",
    "            \n",
    "            for name in names:\n",
    "            \n",
    "                x = samples_uniform[name]\n",
    "                \n",
    "                #old uniform distribution\n",
    "                i = problem['names'].index(name)\n",
    "                width = bounds[i,1]-bounds[i,0]\n",
    "                \n",
    "                #convert x to percentages q\n",
    "                q = [xx/width for xx in x]\n",
    "                \n",
    "                #new triangular distribution, convert loc, scale and c taken from \"bw\" to \"stats.triang\" definition\n",
    "                #in bw:           input_factor (or params): 'minimum' < loc' < 'maximum'\n",
    "                #in stats.triang: triangular distribution with an up-sloping line from loc to (loc + c*scale) \n",
    "                #                 and then downsloping for (loc + c*scale) to (loc+scale).\n",
    "                input_factor = params[params['i']==int(name)]\n",
    "                loc   = input_factor['minimum']\n",
    "                scale = input_factor['maximum']-input_factor['minimum']\n",
    "                c     = (input_factor['loc']-loc)/scale\n",
    "                \n",
    "                #Converted samples generated using ppf (=inverse of cdf)\n",
    "                samples_conv[name] = triang.ppf(q,c=c,loc=loc,scale=scale)\n",
    "                \n",
    "        return samples_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[0.33378330925116406, 0.99865010196837, 0.6662167204706981, 0.001349898031630048]\n",
      "4\n",
      "[0.6662167204706981, 0.001349898031630048, 0.33378330925116406, 0.99865010196837]\n",
      "4\n",
      "[0.33378330925116406, 0.99865010196837, 0.001349898031630048, 0.6662167204706981]\n",
      "4\n",
      "[0.33378330925116406, 0.99865010196837, 0.001349898031630048, 0.6662167204706981]\n",
      "4\n",
      "[0.33378330925116406, 0.99865010196837, 0.001349898031630048, 0.6662167204706981]\n",
      "4\n",
      "[0.001349898031630048, 0.6662167204706981, 0.99865010196837, 0.33378330925116406]\n",
      "4\n",
      "[0.001349898031630048, 0.6662167204706981, 0.33378330925116406, 0.99865010196837]\n",
      "4\n",
      "[0.001349898031630048, 0.6662167204706981, 0.33378330925116406, 0.99865010196837]\n",
      "4\n",
      "[0.33378330925116406, 0.99865010196837, 0.001349898031630048, 0.6662167204706981]\n",
      "4\n",
      "[0.33378330925116406, 0.99865010196837, 0.001349898031630048, 0.6662167204706981]\n"
     ]
    }
   ],
   "source": [
    "samples_lg = obtain_original_pdf(problem,params,samples_dt,id_lg)\n",
    "samples_nm = obtain_original_pdf(problem,params,samples_dt,id_nm)\n",
    "samples_tr = obtain_original_pdf(problem,params,samples_dt,id_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate area under 6 sigma interval of the normal distribution\n",
    "from math import exp, pi\n",
    "from scipy.integrate import quad\n",
    "s = 1\n",
    "m = 0\n",
    "six_sigma_q = quad(lambda x: 1/np.sqrt(2*pi*s**2)*exp(-(x-m)**2/(2*s**2)),-3*s, 3*s)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "think about the computational effort\n",
    "- how many calculations are needed for a reasonable result?\n",
    "- how much time is it?\n",
    "\n",
    "optimize code, only a few levels are used so no need to run ppf all the time\n",
    "\n",
    "combine samples together and run morris.analyze\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Morris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple 2 variable example to check distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SALib.sample import morris\n",
    "from scipy.stats import lognorm, norm, triang\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate area under 6 sigma interval of the normal distribution\n",
    "from math import exp, pi\n",
    "from scipy.integrate import quad\n",
    "s = 1\n",
    "m = 0\n",
    "six_sigma_q = quad(lambda x: 1/np.sqrt(2*pi*s**2)*exp(-(x-m)**2/(2*s**2)),-3*s, 3*s)[0]\n",
    "six_sigma_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vars = 2\n",
    "names = ['x1','x2']\n",
    "bounds = [[0,1],[0,7]]\n",
    "problem = {\n",
    "    'num_vars': n_vars,\n",
    "    'names':    names,\n",
    "    'bounds':   bounds\n",
    "}\n",
    "n_tra = 1000\n",
    "p = 1000\n",
    "samples = morris.sample(problem, N=n_tra, num_levels=p)\n",
    "N = samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 1\n",
    "x = samples[:,ind]\n",
    "#old uniform distribution\n",
    "width = bounds[ind][1]-bounds[ind][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Lognormal\n",
    "\n",
    "#convert x to percentages q\n",
    "q = [xx*six_sigma_q/width+(1-six_sigma_q)/2 for xx in x]\n",
    "#new lognormal\n",
    "mu = 0\n",
    "sigma = 0.5\n",
    "shift = 0\n",
    "#Converted samples generated using ppf (=inverse of cdf)\n",
    "y = lognorm.ppf(q,s=sigma,loc=shift,scale=np.exp(mu))\n",
    "\n",
    "fig = plt.hist(y,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Normal\n",
    "#convert x to percentages q\n",
    "q = [xx*six_sigma_q/width+(1-six_sigma_q)/2 for xx in x]\n",
    "#ql = 0.0015\n",
    "#qu = 0.9985\n",
    "#q = [max(qq,ql) for qq in q]\n",
    "#q = [min(qq,qu) for qq in q]\n",
    "#new normal\n",
    "mu = 0\n",
    "sigma = 0.5 \n",
    "#Converted samples generated using ppf (=inverse of cdf)\n",
    "y = norm.ppf(q,loc=mu,scale=sigma)\n",
    "\n",
    "fig = plt.hist(y,150,density=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Triangular\n",
    "#convert x to percentages q\n",
    "q = [xx/width for xx in x]\n",
    "#new triangular\n",
    "loc   = 0.01\n",
    "scale = 0.11\n",
    "c     = 0.9\n",
    "#Converted samples generated using ppf (=inverse of cdf)\n",
    "y = triang.ppf(q,c=c,loc=loc,scale=scale)\n",
    "\n",
    "fig = plt.hist(y,150,density=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import quad\n",
    "from math import pi, exp, log\n",
    "from scipy.stats import norm, triang, lognorm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO determine 6 sigma for lognormal\n",
    "s = 1\n",
    "m = 0\n",
    "#quad(lambda x: 1/np.sqrt(2*pi*s**2)*exp(-(x-m)**2/(2*s**2)),-3*s, 3*s)\n",
    "quad(lambda x: 1/np.sqrt(2*pi*(s**2)*(x**2))*exp(-(log(x)-m)**2/(2*(s**2))),0,4*s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "x = samples_dt['19640']\n",
    "c = 0.8\n",
    "loc = 0\n",
    "scale = 1\n",
    "ax.plot(x, norm.pdf(x),'r-', lw=5, alpha=0.6, label='triang pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run LCI and LCIA with tech_params with new samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Create new vector \"amounts\" of size n_params but with new sampled values\n",
    "amount = lca.tech_params['amount']\n",
    "score = np.zeros(N)\n",
    "i = 0\n",
    "for x in samples:\n",
    "    if not (i % 50):\n",
    "        print(i)\n",
    "    amount[all_triang['i']] = x\n",
    "    lca.tech_params['amount'] = amount\n",
    "    lca.rebuild_technosphere_matrix(lca.tech_params['amount'])\n",
    "    lca.redo_lci()\n",
    "    lca.redo_lcia()\n",
    "    score[i] = lca.score\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new vector \"amounts\" of size n_params but with new sampled values\n",
    "amount = lca.tech_params['amount']\n",
    "score = np.zeros(N)\n",
    "i = 0\n",
    "amount[all_triang['i']] = samples[90]\n",
    "lca.tech_params['amount'] = amount\n",
    "lca.rebuild_technosphere_matrix(lca.tech_params['amount'])\n",
    "lca.redo_lci()\n",
    "lca.redo_lcia()\n",
    "#score[i] = lca.score\n",
    "#i += 1\n",
    "lca.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.distributions import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [12.10.2018] Elementary effect method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Si = morris.analyze(problem, X, Y, conf_level=0.95, print_to_console=True, num_levels=4, grid_jump=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertain_params = lca.tech_params\n",
    "\n",
    "def formulate_salib_problem(uncertain_params):\n",
    "    \n",
    "    stats_array_2_salib(uncertain_params)\n",
    "    \n",
    "    num_vars = len(uncertain_params)\n",
    "    \n",
    "    #Assign names to all tech_params according to their matrix position\n",
    "    names = [str(x) for x in range(num_vars)]\n",
    "    \n",
    "    bounds = []\n",
    "    \n",
    "    return num_vars, names, bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp, sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_array_2_salib(vec):\n",
    "    \"\"\"\n",
    "    Function that converts uncertainty info from stats_array format to salib format\n",
    "    \n",
    "    stats_array format: https://stats-arrays.readthedocs.io/en/latest/index.html#params-array\n",
    "    salib format: https://github.com/SALib/SALib/blob/master/SALib/util/__init__.py\n",
    "    \"\"\"\n",
    "    \n",
    "    #IDs from stats_array\n",
    "    id_uniform = 4\n",
    "    id_triang = 5\n",
    "    id_normal = 3\n",
    "    id_lognorm = 2\n",
    "    \n",
    "    #Uniform\n",
    "    if vec['uncertainty_type'] == id_uniform:\n",
    "        dists = ['unif', vec['minimum'], vec['maximum']]\n",
    "    #Triangular\n",
    "    elif vec['uncertainty_type'] == id_triang:\n",
    "        width = vec['maximum']-vec['minimum']\n",
    "        peak = (vec['loc']-vec['minimum'])/float(width)\n",
    "        dists = ['triang', width, peak, vec['minimum']]\n",
    "    #Normal\n",
    "    elif vec['uncertainty_type'] == id_normal:\n",
    "        dists = ['norm', vec['loc'], vec['scale']]\n",
    "    #Lognormal\n",
    "    elif ['uncertainty_type'] == id_lognorm:\n",
    "        m = vec['loc']   #mean of the underlying normal distribution\n",
    "        s = vec['scale'] #std  of the underlying normal distribution\n",
    "        ln_mean = exp(m + s**2/2)\n",
    "        ln_std = sqrt((exp(s**2)-1)*exp(2*m+s**2))\n",
    "        dists = ['lognorm', ln_mean, ln_std]\n",
    "    else:\n",
    "        dists = []\n",
    "        \n",
    "    return dists\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_array_2_salib_all(vecs):\n",
    "    for x in vecs:\n",
    "        #Create a dictionary with tech_params and uncertainty info on them\n",
    "        if x[6] ~= 0:\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_array_2_salib(lca.tech_params[16026])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0\n",
    "for i in range(lca.tech_params.shape[0]):\n",
    "    #Create a dictionary with tech_params and uncertainty info on them\n",
    "    if lca.tech_params[i][5] == 5:\n",
    "        s+=1\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lca.tech_params[16026][]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For the given demand vector run Monte Carlo simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stats_arrays as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First local MC, only change A[1,2681]\n",
    "for j in range(len(act_lci.tech_params)):\n",
    "    if ((act_lci.tech_params[j][\"row\"]==1) and (act_lci.tech_params[j][\"col\"]==2681)):\n",
    "        break\n",
    "index = j\n",
    "A_1_2681 = act_lci.tech_params[index]\n",
    "#Specify distribution parameters (as they are given by ecoinvent)\n",
    "A_1_2681_params = {key:value for (key,value) in zip(A_1_2681.dtype.names,A_1_2681)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random number generator\n",
    "A_1_2681_gen = st.MCRandomNumberGenerator(st.UncertaintyBase.from_dicts(A_1_2681_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of MC simulations\n",
    "N = 10\n",
    "samples = np.zeros(N)\n",
    "supply  = np.zeros((N,act_lci.inventory.shape[0]))\n",
    "for i in range(N):\n",
    "    samples[i] = next(A_1_2681_gen)\n",
    "    temp = copy.deepcopy(act_lci.tech_params[:][\"amount\"])\n",
    "    temp[index] = samples[i]\n",
    "    act_lci.rebuild_technosphere_matrix(temp)\n",
    "    act_lci.redo_lci()\n",
    "    supply[i,:] = np.sum(act_lci.inventory,axis=1).A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First order sensitivity indices\n",
    "si_first = np.var(samples)/np.var(supply)\n",
    "#si_total = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
