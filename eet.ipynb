{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brightway2 as bw\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose a project and run LCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw.projects.set_current(\"SA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Databases dictionary with 2 object(s):\n",
       "\tbiosphere3\n",
       "\tecoinvent 3.5 cutoff"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bw.databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'ecoinvent 3.5 cutoff'\n",
    "db = bw.Database(db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "act = db.random()\n",
    "act_amount = 1.0 #unit demand vector\n",
    "ipcc2013 = [m for m in bw.methods if 'IPCC' in m[0]\n",
    "                        and ('2013') in str(m)\n",
    "                        and 'GWP 100' in str(m)\n",
    "                        and 'no LT' not in str(m)]\n",
    "lca = bw.LCA({act:act_amount}, ipcc2013[0])\n",
    "lca.lci()\n",
    "lca.lcia()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. create a vector tech_params identical to lca.tech_params but with an additional column for indices $1,2,...,n_{params}$ and dtype.name $i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#augmented dtype\n",
    "dt = lca.tech_params.dtype.descr\n",
    "dt.insert(0,('i','<i4'))\n",
    "dt = np.dtype(dt)\n",
    "\n",
    "#number of parameters\n",
    "n_params = lca.tech_params.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lca.tech_params augmented with the index on the first position\n",
    "tech_params = np.zeros([n_params],dtype=dt)\n",
    "i = 0\n",
    "for x in lca.tech_params:\n",
    "    temp = list(x)\n",
    "    temp.insert(0,i)\n",
    "    tech_params[i] = tuple(temp)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate samples for EET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate uniformly distributed samples ($\\in [0,1]$) using SALib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SALib.sample import morris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IDs for distributions from stats_array\n",
    "id_na = 0 #no distribution available\n",
    "id_lg = 2 #lognormal\n",
    "id_nm = 3 #normal\n",
    "id_tr = 5 #triangular\n",
    "\n",
    "#all uncertain parameters\n",
    "#params = tech_params[tech_params['uncertainty_type']==id_tr]\n",
    "params = tech_params[tech_params['uncertainty_type']==id_tr] #TODO change to this eventually\n",
    "n_vars = len(params)\n",
    "names  = [str(x) for x in params['i']]\n",
    "bounds = np.array([np.zeros(n_vars),np.ones(n_vars)]).T #Always [0,1]!\n",
    "problem = {\n",
    "    'num_vars': n_vars,\n",
    "    'names':    names,\n",
    "    'bounds':   bounds,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate samples\n",
    "n_tra = 20          #number of trajectories\n",
    "p     = 4           #number of levels, even number recommended\n",
    "delta = p/(2*(p-1)) #grid jump recommended in papers\n",
    "samples = morris.sample(problem, n_tra, num_levels=p)\n",
    "N = samples.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1960"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert uniform samples to original distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import lognorm, norm, triang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#give dtype with names to distinguish between input factors\n",
    "data_type = [('<f4') for x in range(n_vars)]\n",
    "dt = np.array([names,data_type]).T\n",
    "dt = [tuple(x) for x in dt]\n",
    "dt = np.dtype(dt)\n",
    "\n",
    "samples_dt = np.zeros([N],dtype = dt)\n",
    "i = 0\n",
    "for x in samples:\n",
    "    temp = list(x)\n",
    "    samples_dt[i] = tuple(temp)\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indices for each distribution\n",
    "ind_lg = params[params['uncertainty_type']==id_lg]['i']\n",
    "ind_nm = params[params['uncertainty_type']==id_nm]['i']\n",
    "ind_tr = params[params['uncertainty_type']==id_tr]['i']\n",
    "#Indices as strings = names\n",
    "names_lg = [str(x) for x in ind_lg]\n",
    "names_nm = [str(x) for x in ind_nm]\n",
    "names_tr = [str(x) for x in ind_tr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Lognormal distribution\n",
    "temp = samples_dt[names_lg]\n",
    "samples_lg = np.zeros(temp.shape)\n",
    "\n",
    "for name in names_lg:\n",
    "    #x is an array of all the sampled values for one input factor\n",
    "    x = samples_dt[name]\n",
    "    \n",
    "    #old uniform distribution\n",
    "    i = list(ind_lg).index(int(name))\n",
    "    width = bounds[i,1]-bounds[i,0]\n",
    "    \n",
    "    #convert x to percentages q\n",
    "    q = [xx/width for xx in x]\n",
    "    ql = 0.0015\n",
    "    qu = 0.9985\n",
    "    q = [max(qq,ql) for qq in q]\n",
    "    q = [min(qq,qu) for qq in q]\n",
    "\n",
    "    #new lognormal distribution\n",
    "    #in bw:            loc=mu, scale=sigma, where mu and sigma are from the normal distribution\n",
    "    #in stats.lognorm: loc=shift, s=sigma, scale=exp(mu), where mu and sigma are from the normal distribution \n",
    "    input_factor = params[params['i']==int(name)]\n",
    "    mu = input_factor['loc']\n",
    "    sigma  = input_factor['scale']\n",
    "    shift = 0\n",
    "    \n",
    "    #Converted samples generated using ppf (=inverse of cdf)\n",
    "    samples_lg[name] = lognorm.ppf(q,s=sigma,loc=shift,scale=np.exp(mu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Normal distribution\n",
    "temp = samples_dt[names_nm]\n",
    "samples_nm = np.zeros(temp.shape)\n",
    "\n",
    "for name in names_nm:\n",
    "    #x is an array of all the sampled values for one input factor\n",
    "    x = samples_dt[name]\n",
    "    \n",
    "    #old uniform distribution\n",
    "    i = list(ind_nm).index(int(name))\n",
    "    width = bounds[i,1]-bounds[i,0]\n",
    "    \n",
    "    #convert x to percentages q\n",
    "    q = [xx/width for xx in x]\n",
    "    ql = 0.0015\n",
    "    qu = 0.9985\n",
    "    q = [max(qq,ql) for qq in q]\n",
    "    q = [min(qq,qu) for qq in q]\n",
    "    \n",
    "    #new normal distribution\n",
    "    #in bw:         loc=mu, scale=sigma, where mu and sigma are mean and std\n",
    "    #in stats.norm: loc=mu, scale=sigma, where mu and sigma are mean and std \n",
    "    input_factor = params[params['i']==int(name)]\n",
    "    mu = input_factor['loc']\n",
    "    sigma  = input_factor['scale']\n",
    "    \n",
    "    #Converted samples generated using ppf (=inverse of cdf)\n",
    "    samples_nm[name] = norm.ppf(q,loc=mu,scale=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Triangular distribution\n",
    "temp = samples_dt[names_tr]\n",
    "samples_tr = np.zeros(temp.shape)\n",
    "\n",
    "for name in names_tr:\n",
    "    #x is an array of all the sampled values for one input factor\n",
    "    x = samples_dt[name]\n",
    "    \n",
    "    #old uniform distribution\n",
    "    i = list(ind_tr).index(int(name))\n",
    "    width = bounds[i,1]-bounds[i,0]\n",
    "    \n",
    "    #convert x to percentages q\n",
    "    q = [xx/width for xx in x]\n",
    "        \n",
    "    #new triangular distribution, convert loc, scale and c taken from \"bw\" to \"stats.triang\" definition\n",
    "    #in bw:           input_factor (or params): 'minimum' < loc' < 'maximum'\n",
    "    #in stats.triang: triangular distribution with an up-sloping line from loc to (loc + c*scale) \n",
    "    #                 and then downsloping for (loc + c*scale) to (loc+scale).\n",
    "    input_factor = params[params['i']==int(name)]\n",
    "    loc   = input_factor['minimum']\n",
    "    scale = input_factor['maximum']-input_factor['minimum']\n",
    "    c     = (input_factor['loc']-loc)/scale\n",
    "    break\n",
    "    \n",
    "    #Converted samples generated using ppf (=inverse of cdf)\n",
    "    samples_tr[name] = triang.ppf(q,c=c,loc=loc,scale=scale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-84cc311ebb8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msamples_tr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "samples_tr[name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "fix samples_tr[name] - got to do with dtype\n",
    "\n",
    "think about the computational effort\n",
    "- how many calculations are needed for a reasonable result?\n",
    "- how much time is it?\n",
    "\n",
    "combine samples together and run morris.analyze\n",
    "\n",
    "ask Chris about dev env and folders of the project. where to keep eet?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Morris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros_like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_dt[names_lg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros_like(samples_dt['19640'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple 2 variable example to check distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SALib.sample import morris\n",
    "from scipy.stats import lognorm, norm, triang\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vars = 4\n",
    "names = ['x','y','z','w']\n",
    "bounds = [[0,1],[0,1],[0,1],[0,1]]\n",
    "groups = ['a','a','b','b']\n",
    "problem = {\n",
    "    'num_vars': n_vars,\n",
    "    'names':    names,\n",
    "    'bounds':   bounds,\n",
    "    'groups':   groups\n",
    "}\n",
    "n_tra = 10000\n",
    "p = 100\n",
    "delta = p/(2*(p-1))\n",
    "samples = morris.sample(problem, N=n_tra, num_levels=p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = samples.T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Lognormal\n",
    "#old uniform distribution\n",
    "width = 1\n",
    "#convert x to percentages q\n",
    "q = [xx/width for xx in x]\n",
    "ql = 0.0015\n",
    "qu = 0.9985\n",
    "q = [max(qq,ql) for qq in q]\n",
    "q = [min(qq,qu) for qq in q]\n",
    "#new lognormal\n",
    "mu = 0\n",
    "sigma = 0.5\n",
    "shift = 0\n",
    "#Converted samples generated using ppf (=inverse of cdf)\n",
    "y = lognorm.ppf(q,s=sigma,loc=shift,scale=np.exp(mu))\n",
    "\n",
    "fig = plt.hist(y,50,density=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Normal\n",
    "#old uniform distribution\n",
    "width = 1\n",
    "#convert x to percentages q\n",
    "q = [xx/width for xx in x]\n",
    "ql = 0.0015\n",
    "qu = 0.9985\n",
    "q = [max(qq,ql) for qq in q]\n",
    "q = [min(qq,qu) for qq in q]\n",
    "#new normal\n",
    "mu = 0\n",
    "sigma = 0.25 \n",
    "#Converted samples generated using ppf (=inverse of cdf)\n",
    "y = norm.ppf(q,loc=mu,scale=sigma)\n",
    "\n",
    "fig = plt.hist(y,50,density=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Triangular\n",
    "#old uniform distribution\n",
    "width = 1\n",
    "#convert x to percentages q\n",
    "q = [xx/width for xx in x]\n",
    "q = max\n",
    "#new triangular\n",
    "loc   = 0.01\n",
    "scale = 0.11\n",
    "c     = 0.9\n",
    "#Converted samples generated using ppf (=inverse of cdf)\n",
    "y = triang.ppf(q,c=c,loc=loc,scale=scale)\n",
    "\n",
    "fig = plt.hist(y,50,density=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import quad\n",
    "from math import pi, exp, log\n",
    "from scipy.stats import norm, triang, lognorm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO determine 6 sigma for lognormal\n",
    "s = 1\n",
    "m = 0\n",
    "#quad(lambda x: 1/np.sqrt(2*pi*s**2)*exp(-(x-m)**2/(2*s**2)),-3*s, 3*s)\n",
    "quad(lambda x: 1/np.sqrt(2*pi*(s**2)*(x**2))*exp(-(log(x)-m)**2/(2*(s**2))),0,4*s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "x = samples_dt['19640']\n",
    "c = 0.8\n",
    "loc = 0\n",
    "scale = 1\n",
    "ax.plot(x, norm.pdf(x),'r-', lw=5, alpha=0.6, label='triang pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run LCI and LCIA with tech_params with new samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Create new vector \"amounts\" of size n_params but with new sampled values\n",
    "amount = lca.tech_params['amount']\n",
    "score = np.zeros(N)\n",
    "i = 0\n",
    "for x in samples:\n",
    "    if not (i % 50):\n",
    "        print(i)\n",
    "    amount[all_triang['i']] = x\n",
    "    lca.tech_params['amount'] = amount\n",
    "    lca.rebuild_technosphere_matrix(lca.tech_params['amount'])\n",
    "    lca.redo_lci()\n",
    "    lca.redo_lcia()\n",
    "    score[i] = lca.score\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new vector \"amounts\" of size n_params but with new sampled values\n",
    "amount = lca.tech_params['amount']\n",
    "score = np.zeros(N)\n",
    "i = 0\n",
    "amount[all_triang['i']] = samples[90]\n",
    "lca.tech_params['amount'] = amount\n",
    "lca.rebuild_technosphere_matrix(lca.tech_params['amount'])\n",
    "lca.redo_lci()\n",
    "lca.redo_lcia()\n",
    "#score[i] = lca.score\n",
    "#i += 1\n",
    "lca.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.distributions import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [12.10.2018] Elementary effect method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Si = morris.analyze(problem, X, Y, conf_level=0.95, print_to_console=True, num_levels=4, grid_jump=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertain_params = lca.tech_params\n",
    "\n",
    "def formulate_salib_problem(uncertain_params):\n",
    "    \n",
    "    stats_array_2_salib(uncertain_params)\n",
    "    \n",
    "    num_vars = len(uncertain_params)\n",
    "    \n",
    "    #Assign names to all tech_params according to their matrix position\n",
    "    names = [str(x) for x in range(num_vars)]\n",
    "    \n",
    "    bounds = []\n",
    "    \n",
    "    return num_vars, names, bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp, sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_array_2_salib(vec):\n",
    "    \"\"\"\n",
    "    Function that converts uncertainty info from stats_array format to salib format\n",
    "    \n",
    "    stats_array format: https://stats-arrays.readthedocs.io/en/latest/index.html#params-array\n",
    "    salib format: https://github.com/SALib/SALib/blob/master/SALib/util/__init__.py\n",
    "    \"\"\"\n",
    "    \n",
    "    #IDs from stats_array\n",
    "    id_uniform = 4\n",
    "    id_triang = 5\n",
    "    id_normal = 3\n",
    "    id_lognorm = 2\n",
    "    \n",
    "    #Uniform\n",
    "    if vec['uncertainty_type'] == id_uniform:\n",
    "        dists = ['unif', vec['minimum'], vec['maximum']]\n",
    "    #Triangular\n",
    "    elif vec['uncertainty_type'] == id_triang:\n",
    "        width = vec['maximum']-vec['minimum']\n",
    "        peak = (vec['loc']-vec['minimum'])/float(width)\n",
    "        dists = ['triang', width, peak, vec['minimum']]\n",
    "    #Normal\n",
    "    elif vec['uncertainty_type'] == id_normal:\n",
    "        dists = ['norm', vec['loc'], vec['scale']]\n",
    "    #Lognormal\n",
    "    elif ['uncertainty_type'] == id_lognorm:\n",
    "        m = vec['loc']   #mean of the underlying normal distribution\n",
    "        s = vec['scale'] #std  of the underlying normal distribution\n",
    "        ln_mean = exp(m + s**2/2)\n",
    "        ln_std = sqrt((exp(s**2)-1)*exp(2*m+s**2))\n",
    "        dists = ['lognorm', ln_mean, ln_std]\n",
    "    else:\n",
    "        dists = []\n",
    "        \n",
    "    return dists\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_array_2_salib_all(vecs):\n",
    "    for x in vecs:\n",
    "        #Create a dictionary with tech_params and uncertainty info on them\n",
    "        if x[6] ~= 0:\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_array_2_salib(lca.tech_params[16026])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0\n",
    "for i in range(lca.tech_params.shape[0]):\n",
    "    #Create a dictionary with tech_params and uncertainty info on them\n",
    "    if lca.tech_params[i][5] == 5:\n",
    "        s+=1\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lca.tech_params[16026][]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For the given demand vector run Monte Carlo simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stats_arrays as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First local MC, only change A[1,2681]\n",
    "for j in range(len(act_lci.tech_params)):\n",
    "    if ((act_lci.tech_params[j][\"row\"]==1) and (act_lci.tech_params[j][\"col\"]==2681)):\n",
    "        break\n",
    "index = j\n",
    "A_1_2681 = act_lci.tech_params[index]\n",
    "#Specify distribution parameters (as they are given by ecoinvent)\n",
    "A_1_2681_params = {key:value for (key,value) in zip(A_1_2681.dtype.names,A_1_2681)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random number generator\n",
    "A_1_2681_gen = st.MCRandomNumberGenerator(st.UncertaintyBase.from_dicts(A_1_2681_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of MC simulations\n",
    "N = 10\n",
    "samples = np.zeros(N)\n",
    "supply  = np.zeros((N,act_lci.inventory.shape[0]))\n",
    "for i in range(N):\n",
    "    samples[i] = next(A_1_2681_gen)\n",
    "    temp = copy.deepcopy(act_lci.tech_params[:][\"amount\"])\n",
    "    temp[index] = samples[i]\n",
    "    act_lci.rebuild_technosphere_matrix(temp)\n",
    "    act_lci.redo_lci()\n",
    "    supply[i,:] = np.sum(act_lci.inventory,axis=1).A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First order sensitivity indices\n",
    "si_first = np.var(samples)/np.var(supply)\n",
    "#si_total = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
